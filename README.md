
Оценочное время 1-2 часа (с точностью не лучше часа)<br>
Фактическое время 1 час 45 мин (не включая это описание)<br>
Вычислительная сложность (функции getPercents) O(N)<br>
Субъективная сложность задачи 2

Для просмотра выполнить команду:<br>
    npm start<br>
(Либо просматривать index.html с открытой консолью браузера)

Реализованный в функции getPercents алгоритм округляет значения процентов до указанного числа знаков. Однако при
суммировании таких независимо округлённых значений общая сумма процентов может быть (и часто) не равна 100. Можно было
бы предложить выборочно изменять некоторые значения (минимизируя при этом вносимую неточность) чтобы полчить сумму точно
100. Однако если речь идёт о юридически значимых цифрах уместно ли такое произвольное изменение? Решил, что не уместно и
реализовывать не стал.

Оценка памяти составит 24 байта на элемент массива процентов плюс 20 байт на каждую строку и около 35 байтов на элемент
входного массива номинальных долей плюс 28-32 байт на каждую строку. В случае длины массивов в 10 000 элементов это
может составит около 1 Мб.

При прогоне на довольно слабой машине (Core2 Duo 2.33GHz, 2Gb RAM) в браузере Chrome (index.html) при больших количестве
элементов время на обработку функцией getPercents одного элемент массива составило около 3 микросекунд, а время на
создание самого входного массива - около 1 микросекунды на элемент. Исходя из этих данных можно выставить ограничение на
размер массива в 1-1.25 миллионов элементов. Конечно, подобные органичения нужно устанавливать основываясь не на одной
тестовой машине, а на каком-то срезе по целевой аудитории. Также нужно принять решение о том, является ли потребность в
памяти для такого количества элементов приемлимой для данной целевой аудитории и для работы остального приложения.
Возможно, что нет, и этот порог стоит существенно опустить - скажем до 500 тысяч или даже до 200 тысяч
